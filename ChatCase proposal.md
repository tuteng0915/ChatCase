# ChatCase 开放域问答测试集构建

* 涂腾

## 背景&思路 

### Why now?


LLMs 的井喷式发展是令人惊异的，对于 LLMs 研究的参与者、支持者、反对者，对当前 LLMs 的能力、风险、透明性、可解释性等问题，存在较大的认知差异。

即使在学术界内，对于 LLMs 的涌现能力的产生原因、表现形式、应用方式也仍然阴云密布，对其局限和风险的理解则更为欠缺。

而目前的大部分 LLMs 基本上采用了同样的技术架构，仅在训练集构建、训练、推理上存在技术差异，各研究主题一味地投入算力增大模型的参数量，形成了类似于军备竞赛的格局，而疏于对模型机制的研究和创新，也造成了大量的人力物力财力的浪费和能源的消耗。

目前的评测数据集（Benchmark）是略显僵硬的，通常只将评测范围限定在经典的文本摘要、阅读理解、常识判断、文本翻译、实体抽取等特定的传统的任务上。

这些评测集为 LLMs 提供了刻板、机械的评测方式，助长了资源的浪费，以及对模型机理的"不求甚解"。

具体而言，传统任务及传统数据集存在以下问题：
* 部分模型有意无意将测试集纳入了训练集，甚至对这些测试集进行了“特训”
* 很多问题可以通过对常识的记忆而完成，无须进行推理
* 测试集的评测目的从认知科学的角度往往是杂糅的

因此，我们想构建一个每个问题都很 Unique 且都有其认知科学、教育学、心理学、语言学背景支持的全新的数据集。


### Why these?

那篇Sparks of AGI也提出了相似的观点，但是他们终究是微软的研究，他们提出了很多 case，都有一定的背景和意义，但是并没能形成一个完善的体系，而且也可能经过了 Cherrypick。

事实上，在互联网中，很容易找到一些具有很强趣味性的问题，例如：

* 蓝牙耳机坏了该去找牙科医生还是耳鼻喉科医生？
* 小红问小明：“小刚怎么还没来。” 小明说：“说曹操曹操到。”请问谁到了？
* 开水是什么角
* （TODO）

这些case看上去都很可笑，甚至被说成是弱智吧的问题，但其实在深入分析后可以发现它们实际上很有门道，它们可能反应了 LLMs 的：
* 指代消歧失败
* 缺少 ToM
* 推理能力流于模式的浅表，而未能与知识和常识融合等
* 同名实体、概念杂糅
* 公理系统杂糅

这些“弱智吧”的题目，显然是不包含在传统数据集中，不太容易被 LLMs 在训练中优化。

这些题目大量流传于互联网，但疏于整理，反而容易使大众对 LLMs 的能力的偏见进行积累。

我们想要建立一个这样的 Case 库，叫 ChatCase，搜集开放域问答的各种 Bad Case，对 LLMs 的认知能力进行评价。

ChatCase 的目标包括：
* 非传统、非典型的测例，防止大模型通过记忆或特训进行作弊
* 题目更加通俗，大众更容易认知，同时在传播中更具有吸引力
* 题目具有其科学意义，对 LLMs 的研究和创新具有指导价值
* 题目并非孤立，具有可扩展性或可构造为 Template



### Why us?

每当一个新的人工智能科研子领域兴起，其数据集一定要先行，但对于测评 LLMs 的认知能力的数据集构建，很多企业、组织、机构都存在一定的阻碍。

对于 OpenAI、Google、百度、科大讯飞等科技公司而言，研究发布新评测集容易被质疑在构建过程中 Cherrypick 了些对自家产品有利的问题，而忽略了自家产品发挥不好的问题。

同时，他们也受限于激烈的竞争环境与舆论压力，只能在内部开展这项工作，而其员工的想象力未必充足。

同样，各个大学的人工智能实验室也未能幸免于这场 LLM 的军备竞赛，由实验室牵头难免得罪同行，也同样容易被质疑作弊和cherrypick的可能性。

媒体等非领域内机构的测评可能并不专业且具有一定的误导性，对于大模型的竞争和发展可能带来负面效果。

## 相关工作（TODO）

Sparks of AGI Paper: https://arxiv.org/pdf/2303.12712.pdf

(如ToM)

威诺格拉德模式挑战
https://www.zhihu.com/question/583588366/answer/2891282508



## 项目设想

### Step 1

**一个倡议性视频 + 现有资源整理**

* 将现有的观点进行梳理，包括，研究该问题的重要意义，研究该问题的方法构想等。
* 发布在b站等平台视频，在内行+外行间获得一定的影响力，获得更多的关注。
* 毕竟，做 Benchmark 得需要人足够多的内行+外行知道，且都觉得有意义才行。

### Step 2

**一个公共文档 + 整理LLMs的回答**

* 公共文档中详细阐述问题的规范
* 什么样的 Case 是 duplicate 的，什么样的 Case 是孤证不立的
* 定期对文档中的问题进行精选，给出市面上尽可能多的LLMs对问题的回答。

### Step 3

**一个自动调用各种LLM接口网站 + 联系认知科学学者和研究机构开展合作**

* 取得更多计算资源与 api token，建立一个网站，当用户做出提问后，实时反馈尽可能多的LLMs对该问题的回答。
* 用户对各个 LLMs 的回答进行打分，构成一个庞大的原始数据集
* 联系认知科学学者和研究机构开展合作，对该原始数据集进行分析和梳理，形成若干个具有强 语言学/认知科学/心理学/教育学 背景的元问题


### Step 4

**一个完善的各种LLM在ChatCase上的评价 + 一系列数据集的发表**

* 对于精选出的元问题构造 Template，批量构建测试集
* 将这些测试集在 LLMs 上进行测试，发布其测试结果
* 持续接受更多 Case，不断丰富 ChatCase

